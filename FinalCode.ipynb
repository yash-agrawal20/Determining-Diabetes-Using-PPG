{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import *\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Butter-Worth Bandpass Filter\n",
    "\n",
    "def butterFil(signal):\n",
    "\n",
    "    filt = butter(5, [0.15, 12], 'bp', fs = 40, output = 'sos')\n",
    "    final = []\n",
    "\n",
    "    for i in range(0, len(signal), 18):\n",
    "        filtered = sosfilt(filt, signal[i:i+18])\n",
    "        for j in filtered:\n",
    "            final.append(j)\n",
    "\n",
    "    #Normalizing the output\n",
    "    ppgMax = max(final)\n",
    "    ppgMin = min(final)\n",
    "    final = (final - ppgMin) / (ppgMax - ppgMin)\n",
    "    \n",
    "    #Length of the signal\n",
    "    t = np.linspace(0,60,len(final))\n",
    "    \n",
    "    ret = [final, t]\n",
    "    return (ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivative Filter\n",
    "\n",
    "def derivativeFil(signal):\n",
    "\n",
    "    sig = []\n",
    "    der1 = []\n",
    "    der2 = []\n",
    "    \n",
    "    #1st Derivative\n",
    "    delta = 0.001\n",
    "    for i in range(1, len(signal)-1):\n",
    "        d = (signal[i+1]-signal[i-1])/(2*delta)\n",
    "        der1.append(d)\n",
    "    \n",
    "    #2nd Derivative\n",
    "    for i in range(1, len(der1)-1):\n",
    "        d = (der1[i+1]-der1[i-1])/(delta**2)\n",
    "        der2.append(d)\n",
    "    \n",
    "    return [der1, der2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Systolic Amplitude\n",
    "\n",
    "def systolic_peak(signal):\n",
    "    \n",
    "    sys_peak = []\n",
    "    for i in range(0, len(signal)-19, 19):\n",
    "        sys_peak.append(max(signal[i:i+19]))\n",
    "    \n",
    "    #Average of the systolic peaks\n",
    "    return sum(sys_peak)/len(sys_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diastolic Amplitude\n",
    "\n",
    "def diastolic_peak(signal):\n",
    "    dia_peak = []\n",
    "    flag = 0\n",
    "    count = 0\n",
    "    #Checking for a change in the slope of the signal from negative to positive\n",
    "    for i in range(0, len(signal)-18, 18):\n",
    "        for j in range(18):\n",
    "            if signal[i+j+1]-signal[i+j]<0:\n",
    "                flag = 1\n",
    "            \n",
    "            #When such a change is detected, the value of the signal at the next index is added to the list of diastolic peaks\n",
    "            if signal[i+j+1]-signal[i+j]>0 and flag == 1:\n",
    "                dia_peak.append(signal[i+j+1])\n",
    "                flag = 0\n",
    "                \n",
    "    diaspeak = 0\n",
    "    c = 0\n",
    "    for i in range(0, len(dia_peak), 2):\n",
    "        diaspeak += dia_peak[i]\n",
    "        c += 1\n",
    "        \n",
    "    #Average of the diastolic peaks\n",
    "    return diaspeak/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulse Interval\n",
    "\n",
    "def pulse_interval(signal, time):\n",
    "    times = []\n",
    "    for i in range(0, len(signal)-19, 19):\n",
    "        times.append(time[signal.index(max(signal[i:i+19]))])\n",
    "    \n",
    "    #Pulse intervals calculated by finding the difference between consecutive systolic peak times\n",
    "    intervals = []\n",
    "    for i in range(len(times)-1):\n",
    "        intervals.append(times[i+1]-times[i])\n",
    "\n",
    "    #Average pulse interval\n",
    "    return sum(intervals)/len(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Signal\n",
    "\n",
    "def getSignal(video_name):\n",
    "\n",
    "    count = 0\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    mean = []\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if (not ret):\n",
    "            break\n",
    "\n",
    "        #Mean value of the red channel of each frame in the video\n",
    "        red = frame[:,:,2]\n",
    "        mean.append(np.mean(red))\n",
    "\n",
    "        # 350 Frames\n",
    "        if count == 350:\n",
    "            break\n",
    "        count += 1\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction\n",
    "\n",
    "def FeatureExtract(video, age):\n",
    "    \n",
    "    # To extract the mean value of the red channel of each frame in the video\n",
    "    signal = getSignal(video)\n",
    "    #Butterworth Filter\n",
    "    new_PPGsignal = butterFil(signal)\n",
    "    PPGsignal = new_PPGsignal[0]\n",
    "\n",
    "    #2nd Order Derivative Features\n",
    "    derFil = derivativeFil(PPGsignal)\n",
    "\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    e = []\n",
    "\n",
    "    for i in range(0, len(derFil[1])-18, 18):\n",
    "\n",
    "        a.append(derFil[1][i+3])\n",
    "        b.append(derFil[1][i+5])\n",
    "        c.append(derFil[1][i+7])\n",
    "        d.append(derFil[1][i+9])\n",
    "        e.append(derFil[1][i+11])\n",
    "    \n",
    "    av = sum(a)/len(a)\n",
    "    bv = sum(b)/len(b)\n",
    "    cv = sum(c)/len(c)\n",
    "    dv = sum(d)/len(d)\n",
    "    ev = sum(e)/len(e)\n",
    "\n",
    "    SysPeak = systolic_peak(PPGsignal)\n",
    "    #Finding DiaStolic Amplitude\n",
    "    DiaPeak = diastolic_peak(PPGsignal)\n",
    "    #Finding the Pulse Interval\n",
    "    t = np.linspace(0, 2.1, len(signal))\n",
    "    pi = pulse_interval(PPGsignal.tolist(), t.tolist())\n",
    "    #Finding the AI\n",
    "    ai = DiaPeak/SysPeak\n",
    "    #Finding the Adjusted AI\n",
    "    adj_AI = 1 - ai\n",
    "    #Finding the ATI/SP\n",
    "    PiSp = pi/SysPeak\n",
    "    #Finding ADJUSTED AI\n",
    "    adj_AI = 1 - ai\n",
    "\n",
    "    featureVector = [age, SysPeak, ai, adj_AI, ev/av, PiSp]\n",
    "    return featureVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe contains equal number of diabetic and non-diabetic patient (38)\n",
    "\n",
    "df1 = pd.read_csv(\"FinalFeatures_train_updated.csv\")\n",
    "Xtrain = df1.iloc[:, 1:7]\n",
    "Ytrain = df1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(Xtest):\n",
    "    lda = LDA()\n",
    "    lda.fit(Xtrain, Ytrain)\n",
    "    ldares = lda.predict(pd.DataFrame(Xtest).T)\n",
    "    print(\"LDA: \", ldares[0])\n",
    "    return ldares[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(Xtest):\n",
    "    logreg = LogisticRegression(random_state=0).fit(Xtrain, Ytrain)\n",
    "    reslr = logreg.predict(pd.DataFrame(Xtest).T)\n",
    "    print(\"Logistic Regression: \", reslr[0])\n",
    "    return reslr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(Xtest):\n",
    "    SVM = svm.SVC()\n",
    "    SVM.fit(Xtrain, Ytrain)\n",
    "    ressvm = SVM.predict(pd.DataFrame(Xtest).T)\n",
    "    print(\"SVM: \", ressvm[0])\n",
    "    return ressvm[00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(Xtest):\n",
    "    trees= tree.DecisionTreeClassifier()\n",
    "    trees.fit(Xtrain, Ytrain)\n",
    "    resdt = trees.predict(pd.DataFrame(Xtest).T)\n",
    "    print(\"Decision Tree: \", resdt[0])\n",
    "    return resdt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recorded Video\n",
    "# httpaddress = \"http://192.168.43.1:8080\"\n",
    "httpaddress = 'Video Dataset/Yash.mp4'\n",
    "age = 20\n",
    "\n",
    "#Extract Patient's Features\n",
    "patient = FeatureExtract(httpaddress, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:  0\n",
      "SVM:  0\n",
      "Decision Tree:  1\n",
      "Logistic Regression:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yash2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but LinearDiscriminantAnalysis was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\yash2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\yash2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\yash2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "decision = lda(patient) + support_vector_machine(patient) + decision_tree(patient) + logistic_regression(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get yourself tested.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final Decisions\n",
    "\n",
    "if decision == 0:\n",
    "    print(\"You are not diabetic.\\n\")\n",
    "elif decision == 1 or decision == 2:\n",
    "    print(\"Get yourself tested.\\n\")\n",
    "else:\n",
    "    print(\"You are diabetic.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
